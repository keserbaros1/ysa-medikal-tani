{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28765fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.metrics import classification_report\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdf66e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])  # grayscale için\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5dd410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıflar: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data_model/'\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'validation', 'test']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n",
    "    for x in ['train', 'validation', 'test']\n",
    "}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(\"Sınıflar:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a5ee7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    for x in ['train', 'validation', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ee28c",
   "metadata": {},
   "source": [
    "## CNN modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b25cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 64 * 64, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (1, 512, 512) -> (16, 256, 256)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (16, 256, 256) -> (32, 128, 128)\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (32, 128, 128) -> (64, 64, 64)\n",
    "        x = x.view(-1, 64 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a61ecb",
   "metadata": {},
   "source": [
    "## Modeli oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model = SimpleCNN(num_classes=len(class_names))\n",
    "scratch_model = scratch_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7601d5",
   "metadata": {},
   "source": [
    "## Loss ve optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(scratch_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe2dc4",
   "metadata": {},
   "source": [
    "## Eğitim başlatma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db3ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_scratch_model = train_model(scratch_model, dataloaders, criterion, optimizer, device, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8c6e8",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b5592f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\keser\\miniconda3\\envs\\ysa_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\keser\\miniconda3\\envs\\ysa_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# İlk katman RGB (3 kanal) bekliyor. 1 kanala uyarladık.\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Son katmanı sınıf sayısına göre değiştirdik.\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0044e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa15084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2652243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "--------------------\n",
      "Train Loss: 2.2079 Acc: 0.1545\n",
      "Validation Loss: 2.1598 Acc: 0.1800\n",
      "\n",
      "Epoch 2/10\n",
      "--------------------\n",
      "Train Loss: 2.1649 Acc: 0.1664\n",
      "Validation Loss: 2.1200 Acc: 0.1822\n",
      "\n",
      "Epoch 3/10\n",
      "--------------------\n",
      "Train Loss: 2.1555 Acc: 0.1716\n",
      "Validation Loss: 2.1325 Acc: 0.1889\n",
      "\n",
      "Epoch 4/10\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, dataloaders, criterion, optimizer, device, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
