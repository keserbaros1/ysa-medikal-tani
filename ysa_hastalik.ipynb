{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfca234",
   "metadata": {},
   "source": [
    "Yapılacaklar:\n",
    "tek seferde sırayla tüm işlemleri yapacak kodu yaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28765fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import copy\n",
    "\n",
    "# import intel_extension_for_pytorch as ipex\n",
    "\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f5989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_choice = 1\n",
    "input_choice = input(\"Seçim yapın:\\n1. CPU için\\n2. GPU (CUDA) için\\n3. XPU (Intel ARC) için\\n (Enter'a basmak CPU seçimi yapar)\\n(1/2/3): \")\n",
    "if input_choice == '1':\n",
    "    device = torch.device(\"cpu\")\n",
    "elif input_choice == '2':\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "elif input_choice == '3':\n",
    "    device = torch.device(\"xpu\") \n",
    "\n",
    "\n",
    "# device = torch.device(\"xpu\" if torch.xpu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf66e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])  # grayscale için\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5dd410e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıflar: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data_model/'\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'validation', 'test']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n",
    "    for x in ['train', 'validation', 'test']\n",
    "}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(\"Sınıflar:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddc024",
   "metadata": {},
   "source": [
    "## Model eğitecek fonksiyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=50, patience=5, class_names=None):\n",
    "    \"\"\"\n",
    "    Derin öğrenme modelini eğitim ve doğrulama verisi üzerinde eğitir.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Eğitilecek PyTorch modeli.\n",
    "        dataloaders (dict): 'train' ve 'validation' anahtarlarına sahip DataLoader sözlüğü.\n",
    "        criterion (loss): Kayıp fonksiyonu.\n",
    "        optimizer (torch.optim): Optimizasyon algoritması.\n",
    "        device (torch.device): Eğitimde kullanılacak cihaz.\n",
    "        num_epochs (int, optional): Maksimum eğitim dönemi sayısı. Varsayılan 50.\n",
    "        patience (int, optional): Early stopping için tekrar süresi (doğruluk gelişmezse durma). Varsayılan 5.\n",
    "        class_names (list, optional): Sınıf isimlerinin listesi. Sınıf bazlı doğruluk ve rapor için kullanılır. Varsayılan None.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Module): En iyi doğrulama başarımına sahip ağırlıklarla geri dönen model.\n",
    "    \"\"\"\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    epochs_no_improve = 0  # Early stopping için sayaç\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 20)\n",
    "\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()   # Eğitim moduna geç\n",
    "            else:\n",
    "                model.eval()    # Değerlendirme moduna geç\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "\n",
    "\n",
    "            # Her batch için döngü\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if phase == 'validation':\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "\n",
    "            # Epoch sonu istatistikleri\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # En iyi doğrulama modelini kaydet\n",
    "            if phase == 'validation':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0  # İyileşme varsa sıfırla\n",
    "                else:\n",
    "                    epochs_no_improve += 1  # İyileşme yoksa artır\n",
    "                print(f'{best_acc}, {epoch_acc}')\n",
    "\n",
    "\n",
    "                # Sınıf bazlı başarı hesaplama\n",
    "                if class_names:\n",
    "                    class_correct = list(0. for i in range(num_classes))\n",
    "                    class_total = list(0. for i in range(num_classes))\n",
    "                    for i in range(len(all_labels)):\n",
    "                        label = all_labels[i]\n",
    "                        pred = all_preds[i]\n",
    "                        if label == pred:\n",
    "                            class_correct[label] += 1\n",
    "                        class_total[label] += 1\n",
    "\n",
    "                    print('\\nSınıf Bazında Doğruluk:')\n",
    "                    for i in range(num_classes):\n",
    "                        if class_total[i] > 0:\n",
    "                            accuracy = 100 * class_correct[i] / class_total[i]\n",
    "                            print(f'Sınıf {i}: {accuracy:.2f}% ({int(class_correct[i])}/{int(class_total[i])})')\n",
    "                        else:\n",
    "                            print(f'Sınıf {i}: Hiç örnek bulunamadı.')\n",
    "\n",
    "\n",
    "                    # Sınıf bazında rapor\n",
    "                    print('\\nSınıf Bazında Rapor:')\n",
    "                    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        # Early stopping kontrolü\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nErken durdurma tetiklendi. Doğrulama doğruluğu {patience} dönemi boyunca gelişmedi.\")\n",
    "            break\n",
    "\n",
    "    # En iyi ağırlıkları geri yükle\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ee28c",
   "metadata": {},
   "source": [
    "## CNN modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b25cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 64 * 64, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (1, 512, 512) -> (16, 256, 256)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (16, 256, 256) -> (32, 128, 128)\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (32, 128, 128) -> (64, 64, 64)\n",
    "        x = x.view(-1, 64 * 64 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88baf58",
   "metadata": {},
   "source": [
    "## CustomCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25748cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # -> (32, 224, 224)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # -> (32, 112, 112)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # -> (64, 56, 56)\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # -> (128, 28, 28)\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                             # -> (256, 14, 14)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a61ecb",
   "metadata": {},
   "source": [
    "## Modeli oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_model = CustomCNN(num_classes=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7601d5",
   "metadata": {},
   "source": [
    "## Loss ve optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe7fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(scratch_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8c6e8",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5592f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# İlk katman RGB (3 kanal) bekliyor. 1 kanala uyarladık.\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Son katmanı sınıf sayısına göre değiştirdik.\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217e3d9",
   "metadata": {},
   "source": [
    "## Eğitime Başlatma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9067c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2652243",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(model, dataloaders, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa1c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "--------------------\n",
      "Train Loss: 2.8750 Acc: 0.1085\n",
      "Validation Loss: 2.1975 Acc: 0.1111\n",
      "0.1111111111111111, 0.1111111111111111\n",
      "\n",
      "Epoch 2/50\n",
      "--------------------\n",
      "Train Loss: 2.1981 Acc: 0.1116\n",
      "Validation Loss: 2.1984 Acc: 0.1133\n",
      "0.11333333333333333, 0.11333333333333333\n",
      "\n",
      "Epoch 3/50\n",
      "--------------------\n",
      "Train Loss: 2.1981 Acc: 0.1094\n",
      "Validation Loss: 2.1973 Acc: 0.1111\n",
      "0.11333333333333333, 0.1111111111111111\n",
      "\n",
      "Epoch 4/50\n",
      "--------------------\n",
      "Train Loss: 2.1982 Acc: 0.1073\n",
      "Validation Loss: 2.1972 Acc: 0.1111\n",
      "0.11333333333333333, 0.1111111111111111\n",
      "\n",
      "Epoch 5/50\n",
      "--------------------\n",
      "Train Loss: 2.1975 Acc: 0.1029\n",
      "Validation Loss: 2.1972 Acc: 0.1111\n",
      "0.11333333333333333, 0.1111111111111111\n",
      "\n",
      "Epoch 6/50\n",
      "--------------------\n",
      "Train Loss: 2.1972 Acc: 0.1048\n",
      "Validation Loss: 2.1977 Acc: 0.1111\n",
      "0.11333333333333333, 0.1111111111111111\n",
      "\n",
      "Epoch 7/50\n",
      "--------------------\n",
      "Train Loss: 2.1980 Acc: 0.1080\n",
      "Validation Loss: 2.1978 Acc: 0.1111\n",
      "0.11333333333333333, 0.1111111111111111\n",
      "\n",
      "Erken durdurma tetiklendi. Doğrulama doğruluğu 5 dönemi boyunca gelişmedi.\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(scratch_model, dataloaders, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6bc38",
   "metadata": {},
   "source": [
    "## Modeli kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"trained_model.pth\"\n",
    "torch.save(trained_model.state_dict(), model_save_path)\n",
    "print(f\"Model başarıyla kaydedildi: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa998ebf",
   "metadata": {},
   "source": [
    "## Modeli yniden oluştur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89181c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN(num_classes=len(class_names))  # Model sınıfınızı yeniden tanımlayın\n",
    "model.load_state_dict(torch.load(\"trained_model.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()  # Modeli değerlendirme moduna alın\n",
    "print(\"Model başarıyla yüklendi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b0ab3",
   "metadata": {},
   "source": [
    "## Modeli Kullanma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = ...  # Yeni bir veri\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    print(f\"Tahmin edilen sınıf: {class_names[preds[0]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ysa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
