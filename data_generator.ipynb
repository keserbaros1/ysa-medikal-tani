{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kullanılan cihaz: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cihaz ayarı\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Kullanılan cihaz:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Görüntülerin bulunduğu dizin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"generated_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hiperparametreler\n",
        "latent_dim = 256  # Latent vektör boyutu, 100 veya 128 de sık kullanılır\n",
        "lr = 0.0001       # Öğrenme oranı\n",
        "batch_size = 32   # Batch büyüklüğü\n",
        "epochs = 300      # Epoch sayısı\n",
        "img_size = 224    # Görüntü boyutu (224x224)\n",
        "ngf = 64          # Generator'deki temel filtre sayısı\n",
        "ndf = 64          # Discriminator'deki temel filtre sayısı\n",
        "num_channels = 1  # Görüntü kanalı sayısı (gri tonlamalı için 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dönüştürmeler\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.Grayscale(num_output_channels=num_channels), # Tek kanala dönüştürme\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * num_channels, [0.5] * num_channels), # Tek kanal için normalizasyon\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, ngf, num_channels):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Giriş: latent_dim x 1 x 1\n",
        "            # Hedef: 7x7'ye çıkarmak için kernel_size=7, stride=1, padding=0 (veya 4x4'e çıkarıp sonraki adımları ayarlayabilirsiniz)\n",
        "            self._block(latent_dim, ngf * 8, 7, 1, 0),  # latent_dim -> ngf*8, 1x1 -> 7x7\n",
        "            self._block(ngf * 8, ngf * 4, 4, 2, 1),    # ngf*8 -> ngf*4,  7x7 -> 14x14\n",
        "            self._block(ngf * 4, ngf * 2, 4, 2, 1),    # ngf*4 -> ngf*2,  14x14 -> 28x28\n",
        "            self._block(ngf * 2, ngf,     4, 2, 1),    # ngf*2 -> ngf,    28x28 -> 56x56\n",
        "            self._block(ngf,     ngf // 2,4, 2, 1),    # ngf   -> ngf//2,  56x56 -> 112x112\n",
        "            # Son katman: Aktivasyon olarak Tanh, num_channels'a çıktı\n",
        "            nn.ConvTranspose2d(ngf // 2, num_channels, kernel_size=4, stride=2, padding=1, bias=False), # ngf//2 -> num_channels, 112x112 -> 224x224\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _block(self, in_c, out_c, k, s, p):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_c, out_c, k, s, p, bias=False),\n",
        "            nn.BatchNorm2d(out_c),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.main(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, num_channels):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Giriş: num_channels x 224 x 224\n",
        "            self._block(num_channels, ndf,       4, 2, 1, use_bn=False), # num_channels -> ndf, 224x224 -> 112x112 (İlk katmanda BN genellikle kullanılmaz)\n",
        "            self._block(ndf,          ndf * 2,   4, 2, 1),               # ndf -> ndf*2, 112x112 -> 56x56\n",
        "            self._block(ndf * 2,      ndf * 4,   4, 2, 1),               # ndf*2 -> ndf*4, 56x56 -> 28x28\n",
        "            self._block(ndf * 4,      ndf * 8,   4, 2, 1),               # ndf*4 -> ndf*8, 28x28 -> 14x14\n",
        "            self._block(ndf * 8,      ndf * 16,  4, 2, 1),               # ndf*8 -> ndf*16, 14x14 -> 7x7\n",
        "            # Son katman: 1x1'e düşürme ve Sigmoid aktivasyonu\n",
        "            nn.Conv2d(ndf * 16, 1, kernel_size=7, stride=1, padding=0, bias=False), # ndf*16 -> 1, 7x7 -> 1x1\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _block(self, in_c, out_c, k, s, p, use_bn=True):\n",
        "        layers = [nn.Conv2d(in_c, out_c, k, s, p, bias=False)]\n",
        "        if use_bn:\n",
        "            layers.append(nn.BatchNorm2d(out_c))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1) # Çıktıyı BCELoss için düzleştir\n",
        "    \n",
        "    # Ağırlıkların başlatılması\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model ve optimizasyon\n",
        "G = Generator(latent_dim, ngf, num_channels).to(device)\n",
        "D = Discriminator(ndf, num_channels).to(device)\n",
        "\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcdGixU9E_aW",
        "outputId": "b1d44a92-a28f-4e37-bc0c-a8ddc5a2d5dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eğitim başlıyor...\n",
            "[Epoch 1/300] [Batch 0/84] Loss_D: 3.7035 (Real: 0.7096, Fake: 2.9939), Loss_G: 13.4701\n",
            "[Epoch 1/300] [Batch 50/84] Loss_D: 7.0943 (Real: 1.7628, Fake: 5.3315), Loss_G: 47.9452\n",
            "[Epoch 2/300] [Batch 0/84] Loss_D: 10.6280 (Real: 6.0302, Fake: 4.5978), Loss_G: 40.3072\n",
            "[Epoch 2/300] [Batch 50/84] Loss_D: 5.1714 (Real: 0.7393, Fake: 4.4320), Loss_G: 37.8550\n",
            "[Epoch 3/300] [Batch 0/84] Loss_D: 4.7590 (Real: 0.6441, Fake: 4.1149), Loss_G: 37.6082\n",
            "[Epoch 3/300] [Batch 50/84] Loss_D: 5.3425 (Real: 1.3762, Fake: 3.9663), Loss_G: 36.3416\n"
          ]
        }
      ],
      "source": [
        "print(\"Eğitim başlıyor...\")\n",
        "\n",
        "image_dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "dataloader = DataLoader(image_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (real_imgs, _) in enumerate(dataloader):\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        b_size = real_imgs.size(0)\n",
        "\n",
        "        # Gerçek ve sahte etiketler\n",
        "        valid = torch.full((b_size,), 0.9, dtype=torch.float, device=device) # Yumuşak etiket\n",
        "        fake = torch.full((b_size,), 0.1, dtype=torch.float, device=device)  # Yumuşak etiket\n",
        "\n",
        "        # ---------------------\n",
        "        #  Discriminator Eğitimi\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Gerçek imajlarla kayıp\n",
        "        real_output = D(real_imgs)\n",
        "        real_loss = criterion(real_output, valid)\n",
        "        # real_loss.backward() # Gradyanları biriktir\n",
        "\n",
        "        # Sahte imajlarla kayıp\n",
        "        z = torch.randn(b_size, latent_dim, 1, 1, device=device) # (batch_size, latent_dim, 1, 1)\n",
        "        fake_imgs = G(z)\n",
        "        fake_output = D(fake_imgs.detach()) # Generator'ün gradyanlarını D eğitimi sırasında dondur\n",
        "        fake_loss = criterion(fake_output, fake)\n",
        "        # fake_loss.backward() # Gradyanları biriktir\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward() # Toplam gradyanı geri yay\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Generator Eğitimi\n",
        "        # -----------------\n",
        "        optimizer_G.zero_grad()\n",
        "        # Sahte imajları Discriminator'den geçir (bu sefer detach() YOK)\n",
        "        # Generator'ün hedefi, Discriminator'ün sahte imajları gerçek olarak sınıflandırmasıdır (valid etiket)\n",
        "        output = D(fake_imgs)\n",
        "        g_loss = criterion(output, valid) # Generator, Discriminator'ı kandırmaya çalışır (valid etiketini hedefleyerek)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if i % 50 == 0: # Her 50 batch'te bir logla\n",
        "            print(\n",
        "                f\"[Epoch {epoch+1}/{epochs}] [Batch {i}/{len(dataloader)}] \"\n",
        "                f\"Loss_D: {d_loss.item():.4f} (Real: {real_loss.item():.4f}, Fake: {fake_loss.item():.4f}), \"\n",
        "                f\"Loss_G: {g_loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    # Her 10 epoch'ta bir ya da son epoch'ta kaydet\n",
        "    if ((epoch + 1) % 10 == 0 or epoch == epochs -1) and (epoch != 0):\n",
        "        with torch.no_grad():\n",
        "            fixed_noise = torch.randn(batch_size, latent_dim, 1, 1, device=device) # Bir batch dolusu örnek üret\n",
        "            sample_batch = G(fixed_noise).detach().cpu()\n",
        "            save_image(sample_batch, f\"generated/epoch_{epoch+1}.png\", nrow=8, normalize=True) # nrow, bir satırda kaç resim olacağını belirler\n",
        "            print(f\"Epoch {epoch+1} için örnek görseller generated/epoch_{epoch+1}.png dosyasına kaydedildi.\")\n",
        "\n",
        "print(\"Eğitim tamamlandı.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ysa_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
